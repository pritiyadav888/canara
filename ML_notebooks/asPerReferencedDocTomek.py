# -*- coding: utf-8 -*-
"""hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I0geuXAj23yLRI_EGs86hX88G6G6clyF
"""

from google.colab import files

files.upload()  # select the kaggle.json file that you downloaded

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d mlg-ulb/creditcardfraud

!unzip creditcardfraud.zip

import pandas as pd

data = pd.read_csv('creditcard.csv')

# # Filter and print one observation with fraudulent activity
fraudulent_observation = data[data['Class'] == 1].head(1)
print(fraudulent_observation)

# print(data.shape)
# print(data.info())
# print(data['Class'].value_counts())

# print(data.isnull().sum())

# print(data.describe())
# print(data.isnull().sum())
# sns.countplot(data['Class'])
# plt.show()

!pip install tpot

!pip install catboost

import pandas as pd
import time
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import (MinMaxScaler, MaxAbsScaler, StandardScaler, PowerTransformer,
                                   QuantileTransformer, Normalizer, FunctionTransformer, PolynomialFeatures, RobustScaler)
from imblearn.under_sampling import TomekLinks
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from catboost import CatBoostClassifier
import xgboost as xgb
import lightgbm as lgb
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix
from tpot import TPOTClassifier
import joblib
import inspect

# Load the dataset
data = pd.read_csv('creditcard.csv')

# Data Visualization
sns.countplot(data['Class'])
plt.title('Class Distribution')
plt.show()

# List of preprocessing options and ML algorithms
preprocessors = [MinMaxScaler, MaxAbsScaler, StandardScaler, PowerTransformer,
                 QuantileTransformer, Normalizer, FunctionTransformer, PolynomialFeatures, RobustScaler]

# Define your classifiers
ml_algorithms = [
    RandomForestClassifier,  # Notice we're not creating an instance here
    AdaBoostClassifier,
    KNeighborsClassifier,
    DecisionTreeClassifier,
    LogisticRegression,
    SVC,
    CatBoostClassifier,
    xgb.XGBClassifier
    # lgb.LGBMClassifier,
    # TPOTClassifier
]


# Placeholder for storing results
results = []

# Define specificity and IBA functions according to the new definitions
def specificity(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    specificity = tn / (tn+fp)
    return specificity

def iba(y_true, y_pred, alpha=0.1):
    recall = recall_score(y_true, y_pred)
    spec = specificity(y_true, y_pred)
    ba = balanced_accuracy_score(y_true, y_pred)
    iba = (1 + alpha * (recall - spec)**2) * ba
    return iba

iba_scorer = make_scorer(iba)

# Placeholder for storing the best classifier and score
best_score = float('-inf')
best_clf = None
# Instantiate preprocessors and ML algorithms outside loops
# Instantiate preprocessors and ML algorithms outside loops
# Instantiate preprocessors and ML algorithms outside loops
preprocessor_instances = [preprocessor() for preprocessor in preprocessors]

ml_algorithm_instances = []
for ml_algorithm in ml_algorithms:
    params = {'random_state': 42} if 'random_state' in inspect.signature(ml_algorithm.__init__).parameters else {}

    if ml_algorithm == RandomForestClassifier:
        params['n_estimators'] = 50

    # if ml_algorithm == TPOTClassifier:
    #     params.update({
    #         'max_time_mins': 45,
    #         'scoring': 'balanced_accuracy',
    #         'n_jobs': -1,
    #         'generations': 5,
    #         'population_size': 20
    #     })

    ml_algorithm_instances.append(ml_algorithm(**params))

results = []


def gmean(y_true, y_pred):
    recall = recall_score(y_true, y_pred)
    spec = specificity(y_true, y_pred)
    return (recall * spec)**0.5

def balanced_metric(y_true, y_pred, dominance=0.1):
    recall = recall_score(y_true, y_pred)
    g_mean = gmean(y_true, y_pred)
    return dominance * recall + (1 - dominance) * g_mean

# for remove_duplicates in [True, False]:
#     for use_tomek_links in [True, False]:
#         for preprocessor in preprocessors:
#             for ml_algorithm in ml_algorithms:

#                 # Preprocessing
#                 temp_data = data.drop_duplicates() if remove_duplicates else data
#                 if use_tomek_links:
#                     tl = TomekLinks()
#                     X_resampled, y_resampled = tl.fit_resample(temp_data.drop('Class', axis=1), temp_data['Class'])
#                 else:
#                     X_resampled, y_resampled = temp_data.drop('Class', axis=1), temp_data['Class']

#                 scaler = preprocessor()
#                 X_scaled = scaler.fit_transform(X_resampled)

#                 # Splitting the dataset
#                 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.3, random_state=42)

#                 # Training and evaluation
#                 clf = ml_algorithm()
#                 clf.fit(X_train, y_train)
#                 y_pred = clf.predict(X_test)

#                 # Cross-validation and IBA calculation
#                 cv_scores = cross_val_score(clf, X_train, y_train, cv=10)
#                 iba_score = iba(y_test, y_pred)

#                 # Storing results
#                 result = {
#                     'Remove Duplicates': remove_duplicates,
#                     'Use Tomek Links': use_tomek_links,
#                     'Preprocessor': preprocessor.__name__,
#                     'ML Algorithm': ml_algorithm.__name__,
#                     'Accuracy': accuracy_score(y_test, y_pred),
#                     'Precision': precision_score(y_test, y_pred),
#                     'Recall': recall_score(y_test, y_pred),
#                     'F1 Score': f1_score(y_test, y_pred),
#                     'CV Score': cv_scores.mean(),
#                     'IBA': iba_score
#                 }
#                 results.append(result)

start_process_time = time.time()  # Start overall process timer

for remove_duplicates in [True, False]:
    temp_data = data.drop_duplicates() if remove_duplicates else data
    for use_tomek_links in [True, False]:
        if use_tomek_links:
            tl = TomekLinks()
            X_resampled, y_resampled = tl.fit_resample(temp_data.drop('Class', axis=1), temp_data['Class'])
        else:
            X_resampled, y_resampled = temp_data.drop('Class', axis=1), temp_data['Class']

        for scaler in preprocessor_instances:
            X_scaled = scaler.fit_transform(X_resampled)
            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)

            for clf in ml_algorithm_instances:
                # Check if overall time is close to 55 minutes and break if so
                if time.time() - start_process_time > 55 * 60:
                    break

                start_time = time.time()  # Start the timer
                print(f"Training with {scaler.__class__.__name__} preprocessor, {clf.__class__.__name__} classifier, remove_duplicates: {remove_duplicates}, use_tomek_links: {use_tomek_links}...")
                clf.fit(X_train, y_train)
                training_time = time.time() - start_time  # End the timer
                print(f"{clf.__class__.__name__} trained in {training_time:.2f} seconds")
                y_pred = clf.predict(X_test)

                # Additional evaluation metrics
                gmean_score = gmean(y_test, y_pred)
                balanced_score = balanced_metric(y_test, y_pred)
                iba_score = iba(y_test, y_pred)
                cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
                cv_scores = cross_val_score(clf, X_scaled, y_resampled, cv=cv, scoring='f1', n_jobs=-1)
                for fold, _ in enumerate(cv.split(X_scaled, y_resampled)):
                  print(f"Processing fold {fold + 1}...")

                result_dict = {
                    'Remove Duplicates': remove_duplicates,
                    'Use Tomek Links': use_tomek_links,
                    'Preprocessor': scaler.__class__.__name__,
                    'ML Algorithm': clf.__class__.__name__,
                    'Accuracy': accuracy_score(y_test, y_pred),
                    'Precision': precision_score(y_test, y_pred),
                    'Recall': recall_score(y_test, y_pred),
                    'F1 Score': f1_score(y_test, y_pred),
                    'Gmean': gmean_score,
                    'Balanced Metric': balanced_score,
                    'CV Score': cv_scores.mean(),
                    'IBA': iba_score
                }

                results.append(result_dict)

                # Checking if the model is the best based on balanced_metric
                if balanced_score > best_score:
                    best_score = balanced_score
                    best_clf = clf
                    print(f"New best score {best_score} found with {clf.__class__.__name__} classifier!")

                 # Break from innermost loop if overall time is close to 55 minutes
            if time.time() - start_process_time > 55 * 60:
                break

        # Break from second innermost loop if overall time is close to 55 minutes
        if time.time() - start_process_time > 55 * 60:
            break

    # Break from outermost loop if overall time is close to 55 minutes
    if time.time() - start_process_time > 55 * 60:
        break

# Convert results to DataFrame for better visualization
results_df = pd.DataFrame(results)

# Saving the best classifier
joblib.dump(best_clf, 'best_model.pkl')

final_cv_scores = cross_val_score(best_clf, X_scaled, y_resampled, cv=10)

# Convert results to DataFrame for easier analysis
results_df = pd.DataFrame(results)

# Result Visualization
plt.figure(figsize=(10, 5))
sns.barplot(data=results_df.sort_values(by='Balanced Metric', ascending=False), x='ML Algorithm', y='Balanced Metric', hue='Preprocessor')
plt.title('Balanced Metric of different ML Algorithms with various Preprocessors')
plt.xticks(rotation=45)
plt.legend(title='Preprocessor', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

print(results_df.sort_values(by='Balanced Metric', ascending=False))

# Convert results to DataFrame for easier analysis
results_df = pd.DataFrame(results)

# Result Visualization
plt.figure(figsize=(10, 5))
sns.barplot(data=results_df.sort_values(by='IBA', ascending=False), x='ML Algorithm', y='IBA', hue='Preprocessor')
plt.title('IBA of different ML Algorithms with various Preprocessors')
plt.xticks(rotation=45)
plt.legend(title='Preprocessor', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

print(results_df.sort_values(by='IBA', ascending=False))

scoring = {
    'accuracy': make_scorer(accuracy_score),
    'precision': make_scorer(precision_score),
    'recall': make_scorer(recall_score),
    'f1': make_scorer(f1_score),
    'iba': make_scorer(balanced_metric)
}

X = temp_data.drop('Class', axis=1)
y = temp_data['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

for name, scoring_method in scoring.items():
    # Classifier training
    clf = ml_algorithm()
    clf.fit(X_train, y_train)

    # Evaluation
    y_pred = clf.predict(X_test)
    score = scoring_method(y_test, y_pred)

    # Storing the results
    results.append({
        'Classifier': ml_algorithm.__name__,
        'Preprocessor': preprocessor.__name__,
        'Remove Duplicates': remove_duplicates,
        'Use Tomek Links': use_tomek_links,
        'Score Type': name,
        'Score': score
    })

    if name == 'accuracy' and score > best_score:
        best_score = score
        best_clf = clf

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Plotting the results similar to the images
plt.figure(figsize=(15, 10))

# Get the top classifiers for demonstration
top_classifiers = results_df['Classifier'].unique()[:5]  # Adjust this for the number of classifiers you want to display

for classifier in top_classifiers:
    subset = results_df[results_df['Classifier'] == classifier]
    plt.plot(subset['Score Type'], subset['Score'], label=classifier)

plt.legend()
plt.title('Classification Results')
plt.xlabel('Score Type')
plt.ylabel('Score Value')
plt.show()

from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)
model = joblib.load('/content/drive/MyDrive/hackathon_Canara/best_model.pkl')  # Load your trained model

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json  # Get the transaction data
    X = pd.DataFrame(data)  # Convert to DataFrame (assuming it's in the right format)
    y_pred = model.predict(X)  # Predict fraud
    return jsonify({'prediction': y_pred.tolist()})  # Return the prediction

if __name__ == '__main__':
    app.run()

print(data.head(10))

import numpy as np

# Choosing the first sample
sample = data.iloc[0].drop('Class')

# Adding small random noise
synthetic_sample = sample + np.random.normal(0, 0.01, size=sample.shape)

# If you want the sample as a DataFrame row:
synthetic_df = pd.DataFrame([synthetic_sample], columns=data.columns[:-1])

print(synthetic_df)

# Using best_clf which is your trained classifier
# Filter and print one observation with fraudulent activity
# Filter and print one observation with fraudulent activity (excluding "Class" feature)
fraudulent_observation = data[data['Class'] == 1].head(1).drop(columns=['Class'])
print(fraudulent_observation)
model = joblib.load('/content/best_model.pkl')  # Load your trained model
# Choosing the first sample
# Choosing the first sample
sample = data.iloc[0].drop('Class').values.reshape(1, -1)
prediction = model.predict(sample)

if prediction[0] == 1:  # Assuming 1 represents 'Fraud' in your encoding
    print("The transaction is Fraudulent.")
else:
    print("The transaction is not Fraudulent.")

# Load your trained model from file
from joblib import load

best_model = load('/content/drive/MyDrive/hackathon_Canara/best_model.pkl')

# Assuming 'Class' column indicates fraud (1 for fraud, 0 for not fraud)
fraud_cases = data[data['Class'] == 1]

# Select the top ten fraud cases (for example, by the highest amount)
top_ten_frauds = fraud_cases.nlargest(10, 'Amount')

# Prepare the features for prediction (excluding the 'Class' column)
X_top_ten_frauds = top_ten_frauds.drop('Class', axis=1)

# Predict using the best model
predictions = best_model.predict(X_top_ten_frauds)

# Print the predictions
print(predictions)