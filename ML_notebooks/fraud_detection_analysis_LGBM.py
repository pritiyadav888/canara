# -*- coding: utf-8 -*-
"""Fraud Detection Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GynV0de0cbijHbyJ-wMTut4NXkQuJcH2

Setup and Data Preparation
This section covers the initial setup, including importing necessary libraries, uploading the Kaggle API key, downloading the dataset, and preparing the data for analysis.

Import Libraries and Setup Kaggle
"""

# Import libraries for file upload and installing packages
from google.colab import files
!pip install -q kaggle

# Upload Kaggle API key
files.upload()  # select the kaggle.json file that you downloaded

# Setup Kaggle directory and permissions
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download and unzip the dataset
!kaggle datasets download -d mlg-ulb/creditcardfraud
!unzip creditcardfraud.zip

#Import Libraries for Data Processing and Modeling

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import joblib
import os
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from imblearn.over_sampling import SMOTE
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

# Load and Prepare Dataset
# Load the dataset
data = pd.read_csv('creditcard.csv')

# Rename V1-V28 for better understanding
for i in range(1, 29):
    data.rename(columns={f'V{i}': f'Component_{i}'}, inplace=True)

# Scale the 'Time' and 'Amount' features
scaler = StandardScaler()
data['Normalized Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))
data['Normalized Time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))

# Drop the original 'Time' and 'Amount' features
data.drop(['Time', 'Amount'], axis=1, inplace=True)

# Split the data into features and targets
X = data.drop('Class', axis=1)
y = data['Class']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(data.head())

"""Model Training and Evaluation"""

# Define and Train Models
models = {
    "Linear Regression": LinearRegression(),
    "Logistic Regression": LogisticRegression(),
    "Quadratic Regression": make_pipeline(PolynomialFeatures(2), LinearRegression()),
    "Naive Bayes": GaussianNB(),
    "KNN": KNeighborsClassifier(),
    "MLP": MLPClassifier(max_iter=1000),
    "LDA": LinearDiscriminantAnalysis(),
    "QDA": QuadraticDiscriminantAnalysis(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "AdaBoost": AdaBoostClassifier()
}

# Create a directory to save models if it doesn't exist
if not os.path.exists('models'):
    os.makedirs('models')

best_model = None
best_f1_score = 0
best_model_name = ""

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Handle continuous predictions for Linear and Quadratic Regression
    if name in ["Linear Regression", "Quadratic Regression"]:
        y_pred = np.where(y_pred > 0.5, 1, 0)

    # Calculate F1 Score
    current_f1_score = f1_score(y_test, y_pred, average='binary')

    # Compare with the best F1 Score
    if current_f1_score > best_f1_score:
        best_f1_score = current_f1_score
        best_model = model
        best_model_name = name

    print(f"Results for {name}:")
    print(classification_report(y_test, y_pred))
    print(confusion_matrix(y_test, y_pred))

    # Save the model
    joblib.dump(model, f'models/{name}_model.pkl')

# Save the best model
if best_model:
    joblib.dump(best_model, f'models/best_model_{best_model_name}.pkl')
    print(f"Best model is '{best_model_name}' with an F1 Score of {best_f1_score}.")

"""Advanced Modeling with Neural Networks"""

# Install TensorFlow (Google Colab should have TensorFlow preinstalled)
# !pip install tensorflow

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

# Load the dataset
data = pd.read_csv('creditcard.csv')

# Rename V1-V28 for better understanding
for i in range(1, 29):
    data.rename(columns={f'V{i}': f'Component_{i}'}, inplace=True)

# Scale the 'Time' and 'Amount' features
scaler = StandardScaler()
data['Normalized Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))
data['Normalized Time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))

# Drop the original 'Time' and 'Amount' features
data.drop(['Time', 'Amount'], axis=1, inplace=True)

# Split the data into features (X) and targets (y) with stratified sampling
X = data.drop('Class', axis=1)
y = data['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Define SMOTE for resampling
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Build the neural network model
model = models.Sequential()
model.add(layers.Dense(256, activation='relu', input_shape=(X_resampled.shape[1],)))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))  # Output layer

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Calculate class weights for imbalanced dataset
class_weights = {
    0: (1 / y_train.value_counts()[0]) * (len(y_train) / 2.0),
    1: (1 / y_train.value_counts()[1]) * (len(y_train) / 2.0)
}

# Train the model with GPU acceleration
history = model.fit(X_resampled, y_resampled,
                    epochs=10,
                    batch_size=512,
                    class_weight=class_weights,
                    validation_data=(X_test, y_test))

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Generate classification report
y_pred = model.predict(X_test) > 0.5  # Convert probabilities to binary output
print(classification_report(y_test, y_pred))

model.save('best_fraud_detection_model.h5')

# Optional: Generate synthetic data to test model performance
smote_test = SMOTE(random_state=42)
X_synthetic, y_synthetic = smote_test.fit_resample(X_test, y_test)
synthetic_loss, synthetic_acc = model.evaluate(X_synthetic, y_synthetic)
print('Synthetic data test accuracy:', synthetic_acc)

# Plotting the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

# Plot training history
pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]
plt.show()

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

plt.tight_layout()
plt.show()

"""Kaggle's approach -https://www.kaggle.com/code/zsinghrahulk/credit-fraud-rf-xgb-lgbm-99-accuracy"""

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
import seaborn as sns
import lightgbm as lgb
from lightgbm import LGBMClassifier
import xgboost as xgb
from sklearn import metrics
from sklearn.metrics import roc_auc_score

# Define the target variable and predictors
data = pd.read_csv('creditcard.csv')
target = 'Class'
predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',
              'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',
              'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',
              'Amount']

# Split the dataset into training and test sets
train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)

# Further split the training set into training and validation sets
train_df, valid_df = train_test_split(train_df, test_size=0.3, random_state=42, shuffle=True)

print(train_df.columns)

clf = RandomForestClassifier(n_jobs=5,
                             random_state=42,
                             criterion='gini',
                             n_estimators=100,
                             verbose=False)
clf.fit(train_df[predictors], train_df[target].values)
preds = clf.predict(valid_df[predictors])

### Feature Importance

tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})
tmp = tmp.sort_values(by='Feature importance',ascending=False)
plt.figure(figsize = (7,4))
plt.title('Features importance',fontsize=14)
s = sns.barplot(x='Feature',y='Feature importance',data=tmp,palette = 'viridis')
s.set_xticklabels(s.get_xticklabels(),rotation=90)
plt.show()

conf_mat = confusion_matrix(valid_df[target], preds )
disp = metrics.ConfusionMatrixDisplay(conf_mat,display_labels = [True,False])
plt.figure(figsize = (10,5))
disp.plot()
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(valid_df[target] , preds)
precision = precision_score(valid_df[target] , preds)
recall = recall_score(valid_df[target] , preds)
f1 = f1_score(valid_df[target] , preds)

new_row = {'model':'RF','accuracy':accuracy , 'precision':precision,'recall':recall ,'f1': f1 }
print(new_row)

# Create an XGBoost model
xgb_model = xgb.XGBClassifier( objective ='binary:logistic', max_depth = 3,  learning_rate = 0.01,   n_estimators = 100 )

# Train the model
xgb_model.fit(train_df[predictors], train_df[target].values)

# Make predictions on the test set
y_pred = xgb_model.predict(valid_df[predictors])

conf_mat = confusion_matrix( valid_df[target] , y_pred )
disp = metrics.ConfusionMatrixDisplay(conf_mat,display_labels = [True,False])
plt.figure(figsize = (10,5))
disp.plot()
plt.show()

accuracy = accuracy_score(valid_df[target] , y_pred)
precision = precision_score(valid_df[target] , y_pred)
recall = recall_score(valid_df[target] , y_pred)
f1 = f1_score(valid_df[target] , y_pred)

new_row = {'model':'XGB','accuracy':accuracy , 'precision':precision,'recall':recall ,'f1': f1 }
print(new_row)

fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))
xgb.plot_importance(xgb_model, height=0.8, title="Features importance (XGBoost)", ax=ax, color="green")
plt.show()

# Make predictions on the test set
y_pred = xgb_model.predict(test_df[predictors])

conf_mat = confusion_matrix( test_df[target] , y_pred )
disp = metrics.ConfusionMatrixDisplay(conf_mat,display_labels = [True,False])
plt.figure(figsize = (10,5))
disp.plot()
plt.show()

accuracy = accuracy_score(test_df[target] , y_pred)
precision = precision_score(test_df[target] , y_pred)
recall = recall_score(test_df[target] , y_pred)
f1 = f1_score(test_df[target] , y_pred)

new_row = {'model':'XGB','accuracy':accuracy , 'precision':precision,'recall':recall ,'f1': f1 }
print(new_row)

"""Techniques such as cross-validation, regularization, and early stopping to prevent overfitting."""

!pip install lightgbm --upgrade

!pip install tabgan==1.3.3

# LightGBM
import lightgbm as lgb
VERBOSE_EVAL = 100
# Create LightGBM datasets
dtrain = lgb.Dataset(train_df[predictors], label=train_df[target])
dvalid = lgb.Dataset(valid_df[predictors], label=valid_df[target])

# Create LightGBM datasets
dtrain = lgb.Dataset(train_df[predictors], label=train_df[target])
dvalid = lgb.Dataset(valid_df[predictors], label=valid_df[target])

# Specify the model configuration
params = {
    'boosting_type': 'gbdt',
    'objective': 'binary',
    'metric': 'auc',
    'learning_rate': 0.05,
    'num_leaves': 7,
    'max_depth': 4,
    'min_child_samples': 100,
    'max_bin': 100,
    'subsample': 0.9,
    'subsample_freq': 1,
    'colsample_bytree': 0.7,
    'min_child_weight': 0,
    'min_split_gain': 0,
    'nthread': 8,
    'verbose': 0,
    'scale_pos_weight': 150,
}

# Train the model with early stopping using callbacks
model = lgb.train(params,
                  dtrain,
                  valid_sets=[dvalid],
                  num_boost_round=1000,
                  callbacks=[lgb.early_stopping(stopping_rounds=100)])

# Plot feature importance
fig, ax = plt.subplots(ncols=1, figsize=(8,5))
lgb.plot_importance(model, height=0.8, title="Features importance (LightGBM)", ax=ax, color="red")
plt.show()

# Make predictions and evaluate
preds = model.predict(test_df[predictors])
roc_score = roc_auc_score(test_df[target].values, preds)
print("ROC AUC Score:", roc_score)